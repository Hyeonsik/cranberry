{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, pickle, sys\n",
    "from scipy import signal\n",
    "\n",
    "\n",
    "### input 설정\n",
    "SRATE = 250 # 250Hz\n",
    "LEN_INPUT = 20 # input 10s\n",
    "LEN_PER_NRS = 60 # vital length for each NRS\n",
    "OVERLAP = 2\n",
    "n_aug = int((LEN_PER_NRS-LEN_INPUT)/OVERLAP) + 1 # data augmentation 개수\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "input_path = 'dataset/preprocess2/input3-2/'\n",
    "if not os.path.exists(input_path[:-1]):\n",
    "    os.mkdir(input_path[:-1])\n",
    "\n",
    "\n",
    "if True:\n",
    "    false_row_list_preop = []\n",
    "    \n",
    "    vital_path = '../../cranberry2/Preprocessing/NRS_vital_pickle_unzip/NRS_vital_pickle'\n",
    "    ecg_path = '../../cranberry2/Preprocessing/ECG_250Hz/ECG_250Hz/ECG,'\n",
    "    df_preprocess_pacu = pickle.load(open('cache/preprocess2/input3/df_preprocess_pacu','rb'))\n",
    "    \n",
    "\n",
    "    ### test set에 해당하는 file_path\n",
    "    filepath_test = pickle.load(open('filepath_test', 'rb'))\n",
    "    caseid_test = np.unique(np.array(pd.Series(filepath_test).str.split(',').tolist())[:,2])\n",
    "\n",
    "    x_train_pacu, y_train_pacu = [], []\n",
    "    x_test_pacu, y_test_pacu = [], []\n",
    "\n",
    "    cnt = 0\n",
    "    for _, row in df_preprocess_pacu.iterrows():\n",
    "        cnt += 1\n",
    "        print('loading data {}/{} ...'.format(cnt, len(df_preprocess_pacu)), end='')\n",
    "\n",
    "        # vital data - PPG (resampling 100 Hz to 250 Hz)\n",
    "        df_vital = pickle.load(open(vital_path+'/'+row['file_path'], 'rb')).reset_index()\n",
    "        pleth_samp = df_vital[['Pleth']].fillna(method='ffill', axis=0).fillna(method='bfill', axis=0).values.flatten()\n",
    "        pleth_resamp = signal.resample(pleth_samp, 120*SRATE)\n",
    "        ppg_per_NRS = np.full(30000, np.nan)\n",
    "        ppg_per_NRS[0:len(pleth_resamp)] = pleth_resamp\n",
    "        \n",
    "\n",
    "        # vital data - ECG (250Hz)\n",
    "        ecg_samp = pickle.load(open(ecg_path+row['file_path'][:-3]+'vital', 'rb')).reset_index()[['ECG']]\n",
    "        ecg_samp = ecg_samp.fillna(method='ffill', axis=0).fillna(method='bfill', axis=0).values.flatten()[0:30000]\n",
    "        ecg_per_NRS = np.full(30000,np.nan)\n",
    "        ecg_per_NRS[0:len(ecg_samp)] = ecg_samp\n",
    "   \n",
    "\n",
    "        # 한 NRS에 대해 23개의 input 확인\n",
    "        for i in range(30,51):\n",
    "            # input이 전처리 통과한 경우\n",
    "            if row[str(i+1)][0]:\n",
    "                start_idx = i*OVERLAP*SRATE # 500i\n",
    "                end_idx = (i*OVERLAP+LEN_INPUT)*SRATE # 500i + 1000\n",
    "\n",
    "\n",
    "                # input의 normalization\n",
    "                pleth_inp = ppg_per_NRS[start_idx:end_idx]\n",
    "                pleth_inp -= np.nanmean(pleth_inp)\n",
    "\n",
    "                ecg_inp = ecg_per_NRS[start_idx:end_idx]\n",
    "                ecg_inp = (ecg_inp - np.nanmean(ecg_inp)) / np.nanstd(ecg_inp)\n",
    "                \n",
    "\n",
    "                # 해당 caseid가 test set에 속하는 경우\n",
    "                if row['caseids'] in caseid_test:\n",
    "                    x_test_pacu.append([pleth_inp, ecg_inp])\n",
    "                    y_test_pacu.append(int(float(row['NRS'])))\n",
    "\n",
    "                # 해당 caseid가 train set에 해당하는 경우\n",
    "                else:\n",
    "                    x_train_pacu.append([pleth_inp, ecg_inp])\n",
    "                    y_train_pacu.append(int(float(row['NRS'])))\n",
    "                    \n",
    "        print('completed')\n",
    "\n",
    "    x_train_pacu = np.array(x_train_pacu, np.float32)\n",
    "    x_test_pacu = np.array(x_test_pacu, np.float32)\n",
    "    y_train_pacu = np.array(y_train_pacu, int)\n",
    "    y_test_pacu = np.array(y_test_pacu, int)\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "print('size of training set(pacu):', len(x_train_pacu))\n",
    "print('size of test set(pacu):', len(x_test_pacu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = 'dataset/preprocess2/input3-2/'\n",
    "\n",
    "# loading pacu\n",
    "print('loading pacu data...', flush=True, end='')\n",
    "x_train_pacu = np.load(input_path+'x_train_pacu.npz', allow_pickle=True)['arr_0']\n",
    "y_train_pacu = np.load(input_path+'y_train_pacu.npz')['arr_0']\n",
    "x_test_pacu = np.load(input_path+'x_test_pacu.npz', allow_pickle=True)['arr_0']\n",
    "y_test_pacu = np.load(input_path+'y_test_pacu.npz')['arr_0']\n",
    "print('done', flush=True)\n",
    "\n",
    "print('x_train_pacu shape:', x_train_pacu.shape)\n",
    "print('x_test_pacu shape:', x_test_pacu.shape)\n",
    "\n",
    "# loading preop\n",
    "print('loading preop data...', flush=True, end='')\n",
    "x_train_preop = np.load(input_path+'x_train_preop.npz', allow_pickle=True)['arr_0']\n",
    "y_train_preop = np.load(input_path+'y_train_preop.npz')['arr_0']\n",
    "x_test_preop = np.load(input_path+'x_test_preop.npz', allow_pickle=True)['arr_0']\n",
    "y_test_preop = np.load(input_path+'y_test_preop.npz')['arr_0']\n",
    "print('done', flush=True)\n",
    "\n",
    "print('x_train_preop shape:', x_train_preop.shape)\n",
    "print('x_test_preop shape:', x_test_preop.shape)\n",
    "\n",
    "\n",
    "# PACU와 preop 데이터 합치기\n",
    "x_train = np.concatenate((x_train_pacu, x_train_preop), axis = 0)\n",
    "y_train = np.concatenate((y_train_pacu, y_train_preop), axis = 0)\n",
    "x_test = np.concatenate((x_test_pacu, x_test_preop), axis = 0)\n",
    "y_test = np.concatenate((y_test_pacu, y_test_preop), axis = 0)\n",
    "\n",
    "\n",
    "# 알맞게 input 변환\n",
    "x_train = np.transpose(x_train, [0,2,1])\n",
    "x_test = np.transpose(x_test, [0,2,1])\n",
    "\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)\n",
    "\n",
    "\n",
    "# filling nan\n",
    "x_train[:,:,0] = pd.DataFrame(x_train[:,:,0]).fillna(method='ffill', axis=1).fillna(method='bfill', axis=1).values\n",
    "x_train[:,:,1] = pd.DataFrame(x_train[:,:,1]).fillna(method='ffill', axis=1).fillna(method='bfill', axis=1).values\n",
    "x_test[:,:,0] = pd.DataFrame(x_test[:,:,0]).fillna(method='ffill', axis=1).fillna(method='bfill', axis=1).values\n",
    "x_test[:,:,1] = pd.DataFrame(x_test[:,:,1]).fillna(method='ffill', axis=1).fillna(method='bfill', axis=1).values\n",
    "\n",
    "y_train_bin = y_train>=5\n",
    "print('train {} ({} events {:.1f}%), test {}'.format(len(y_train_bin), sum(y_train_bin), 100*np.mean(y_train_bin), len(x_test)))\n",
    "\n",
    "\n",
    "# 저장하기 - completed train, test set\n",
    "print('saving...', end='', flush=True)\n",
    "np.savez_compressed(input_path+'x_train.npz', x_train)\n",
    "np.savez_compressed(input_path+'x_test.npz', x_test)\n",
    "np.savez_compressed(input_path+'y_train.npz', y_train)\n",
    "np.savez_compressed(input_path+'y_test.npz', y_test)\n",
    "print('done', flush=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
