{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T05:57:54.063667Z",
     "start_time": "2020-12-12T05:56:05.219268Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2567\n",
      "PACU1_5_190816_164448.csv [190816007, 190816097]\n",
      "PACU1_5_190816_164448.csv [190816007, 190816097]\n",
      "PACU1_1_200916_162304.csv [200916045, 200916064]\n",
      "PACU1_1_200916_162304.csv [200916045, 200916064]\n"
     ]
    }
   ],
   "source": [
    "df_match = pd.read_csv('match_pass_setvalue_20201211.csv')\n",
    "\n",
    "uni=[]\n",
    "dupl=[]\n",
    "idx=[]\n",
    "for i in range(len(df_match)):\n",
    "    if df_match.loc[i,'path'] in uni:\n",
    "        dupl.append(df_match.loc[i,'path'])\n",
    "        idx.append(i)\n",
    "    else:\n",
    "        uni.append(df_match.loc[i,'path'])\n",
    "print(len(dupl))\n",
    "\n",
    "df_dupl = df_match.loc[idx]\n",
    "df_dupl.reset_index(inplace=True)\n",
    "\n",
    "for k in dupl:\n",
    "    same=[]\n",
    "    for j in range(len(df_dupl)):\n",
    "        if df_dupl.loc[j,'path'] == k:\n",
    "            while df_dupl.loc[j,'opid'] not in same:\n",
    "                same.append(df_dupl.loc[j,'opid'])\n",
    "    if len(same)>1:\n",
    "        print(k,same)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T06:00:23.260324Z",
     "start_time": "2020-12-12T06:00:21.928527Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42185291 190816007 1.0 0.0 nan PACU1_5_190816_135540.csv\n",
      "37501620 190816097 nan 1.0 nan PACU1_5_190816_164448.csv\n",
      "42185291 190816007 nan 1.0 nan PACU1_5_190816_164448.csv\n",
      "37501620 190816097 nan 1.0 nan PACU1_5_190816_164448.csv\n",
      "54257221 200916064 nan nan 1.0 PACU1_1_200916_105418.csv\n",
      "54257221 200916064 nan nan 1.0 PACU1_1_200916_105418.csv\n",
      "54047479 200916045 1.0 nan nan PACU1_1_200916_162304.csv\n",
      "54047479 200916045 1.0 nan nan PACU1_1_200916_162304.csv\n",
      "54257221 200916064 1.0 nan 0.0 PACU1_1_200916_162304.csv\n",
      "385\n",
      "358\n",
      "3201\n"
     ]
    }
   ],
   "source": [
    "testtrain = [190816007, 190816097, 200916045,200916064]\n",
    "\n",
    "df_match = pd.read_csv('match_pass_setvalue_20201211.csv')\n",
    "\n",
    "for _, row in df_match.iterrows():\n",
    "    if row['opid'] in testtrain:\n",
    "        print(row['hid'],row['opid'],row['test'],row['train'],row['val'],row['path'])\n",
    "        \n",
    "df_path = df_match.drop_duplicates(subset=['path'],keep='first')\n",
    "\n",
    "print(len(df_path[df_path['test']==1]))\n",
    "print(len(df_path[df_path['val']==1]))\n",
    "print(len(df_path[df_path['train']==1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T05:32:13.374420Z",
     "start_time": "2020-12-12T05:32:12.112479Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190816007 1.0 0.0 nan PACU1_5_190816_135540.csv\n",
      "190816007 nan 1.0 nan PACU1_5_190816_164448.csv\n",
      "200303040 1.0 0.0 nan PACU1_5_200303_124705.csv\n",
      "200303040 nan 1.0 nan PACU1_5_200303_130223.csv\n",
      "200313088 1.0 0.0 nan PACU1_4_200313_155044.csv\n",
      "200313088 1.0 0.0 nan PACU1_4_200313_155044.csv\n",
      "200313088 nan 1.0 nan PACU1_4_200313_170104.csv\n",
      "200916064 nan nan 1.0 PACU1_1_200916_105418.csv\n",
      "200916064 nan nan 1.0 PACU1_1_200916_105418.csv\n",
      "200916064 1.0 nan 0.0 PACU1_1_200916_162304.csv\n",
      "385\n",
      "358\n",
      "3201\n"
     ]
    }
   ],
   "source": [
    "testtrain = [190816007, 200303040, 200313088,200916064]\n",
    "\n",
    "df_match = pd.read_csv('match_pass_setvalue_20201211.csv')\n",
    "\n",
    "for _, row in df_match.iterrows():\n",
    "    if row['opid'] in testtrain:\n",
    "        print(row['opid'],row['test'],row['train'],row['val'],row['path'])\n",
    "        \n",
    "df_path = df_match.drop_duplicates(subset=['path'],keep='first')\n",
    "\n",
    "print(len(df_path[df_path['test']==1]))\n",
    "print(len(df_path[df_path['val']==1]))\n",
    "print(len(df_path[df_path['train']==1]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T06:15:37.378873Z",
     "start_time": "2020-12-12T06:15:37.361066Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "384\n",
      "354\n",
      "3185\n"
     ]
    }
   ],
   "source": [
    "df_opid = df_match.drop_duplicates(subset=['opid'],keep='first')\n",
    "\n",
    "print(len(df_opid[df_opid['test']==1]))\n",
    "print(len(df_opid[df_opid['val']==1]))\n",
    "print(len(df_opid[df_opid['train']==1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T05:44:41.595317Z",
     "start_time": "2020-12-12T05:44:40.402602Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37501620 190816097\n",
      "42185291 190816007\n",
      "37501620 190816097\n"
     ]
    }
   ],
   "source": [
    "testtrain = [190816007, 200303040, 200313088,200916064]\n",
    "\n",
    "df_match = pd.read_csv('match_pass_setvalue_20201211.csv')\n",
    "for _, row in df_match.iterrows():\n",
    "    if row['path']=='PACU1_5_190816_164448.csv':\n",
    "        print(row['hid'],row['opid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T06:36:26.539022Z",
     "start_time": "2020-12-12T06:36:25.001890Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190816007 1 0 0 PACU1_5_190816_135540.csv\n",
      "190816007 1 0 0 PACU1_5_190816_164448.csv\n",
      "200303040 1 0 0 PACU1_5_200303_124705.csv\n",
      "200303040 1 0 0 PACU1_5_200303_130223.csv\n",
      "200313088 1 0 0 PACU1_4_200313_155044.csv\n",
      "200313088 1 0 0 PACU1_4_200313_155044.csv\n",
      "200313088 1 0 0 PACU1_4_200313_170104.csv\n",
      "200916064 1 0 0 PACU1_1_200916_105418.csv\n",
      "200916064 1 0 0 PACU1_1_200916_105418.csv\n",
      "200916064 1 0 0 PACU1_1_200916_162304.csv\n",
      "6511\n",
      "6505\n"
     ]
    }
   ],
   "source": [
    "testtrain = [190816007, 200303040, 200313088,200916064]\n",
    "\n",
    "df_match = pd.read_csv('match_pass_setvalue_20201211.csv')\n",
    "\n",
    "for _, row in df_match.iterrows():\n",
    "    if row['opid'] in testtrain:\n",
    "        row['train']=0\n",
    "        row['val']=0\n",
    "        row['test']=1\n",
    "        print(row['opid'],row['test'],row['train'],row['val'],row['path'])\n",
    "\n",
    "droplist=[]\n",
    "for l in range(len(df_match)):\n",
    "    if df_match.loc[l,'path'] == 'PACU1_1_200916_162304.csv':\n",
    "        droplist.append(l)\n",
    "    if df_match.loc[l,'path'] == 'PACU1_5_190816_164448.csv':\n",
    "        droplist.append(l)\n",
    "\n",
    "print(len(df_match))\n",
    "df_match.drop(droplist,inplace=True)\n",
    "print(len(df_match))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T06:42:55.616745Z",
     "start_time": "2020-12-12T06:42:54.819978Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "384\n",
      "358\n",
      "3200\n",
      "190816007 1 0 0 PACU1_5_190816_135540.csv\n",
      "200303040 1 0 0 PACU1_5_200303_124705.csv\n",
      "200303040 1 0 0 PACU1_5_200303_130223.csv\n",
      "200313088 1 0 0 PACU1_4_200313_155044.csv\n",
      "200313088 1 0 0 PACU1_4_200313_170104.csv\n",
      "200916064 1 0 0 PACU1_1_200916_105418.csv\n",
      "384\n",
      "3200\n",
      "358\n",
      "387\n",
      "3198\n",
      "357\n"
     ]
    }
   ],
   "source": [
    "#df_path = df_match.drop_duplicates(subset=['path'],keep='first')\n",
    "#df_path=df_match\n",
    "df_path = df_match.drop_duplicates(subset=['path'],keep='first')\n",
    "\n",
    "print(len(df_path[df_path['test']==1]))\n",
    "print(len(df_path[df_path['val']==1]))\n",
    "print(len(df_path[df_path['train']==1]))\n",
    "\n",
    "for _, row in df_path.iterrows():\n",
    "    if row['opid'] in testtrain:\n",
    "        row['train']=0\n",
    "        row['val']=0\n",
    "        row['test']=1\n",
    "        print(row['opid'],row['test'],row['train'],row['val'],row['path'])\n",
    "\n",
    "df_test=df_path[df_path['test']==1]\n",
    "df_train=df_path[df_path['train']==1]\n",
    "df_val= df_path[df_path['val']==1]\n",
    "caseid_test = df_test['path']\n",
    "caseid_train = df_train['path']\n",
    "caseid_val = df_val['path']\n",
    "\n",
    "caseid_test=np.array(caseid_test)\n",
    "caseid_train=np.array(caseid_train)\n",
    "caseid_val=np.array(caseid_val)\n",
    "\n",
    "caseid_test = np.unique(caseid_test)\n",
    "caseid_train = np.unique(caseid_train)\n",
    "caseid_val = np.unique(caseid_val)\n",
    "\n",
    "caseid_test = caseid_test.tolist()\n",
    "caseid_train= caseid_train.tolist()\n",
    "caseid_val= caseid_val.tolist()\n",
    "print(len(caseid_test))\n",
    "print(len(caseid_train))\n",
    "print(len(caseid_val))\n",
    "\n",
    "\n",
    "path_list=['PACU1_5_190816_135540.csv','PACU1_5_200303_124705.csv','PACU1_5_200303_130223.csv','PACU1_4_200313_155044.csv','PACU1_4_200313_170104.csv','PACU1_1_200916_105418.csv']\n",
    "for p in path_list:\n",
    "    while p in caseid_train:\n",
    "        caseid_train.remove(p)\n",
    "        caseid_test.append(p)\n",
    "        \n",
    "    while p in caseid_val:\n",
    "        caseid_val.remove(p)\n",
    "        caseid_test.append(p)\n",
    "        \n",
    "caseid_test=np.array(caseid_test)\n",
    "caseid_train=np.array(caseid_train)\n",
    "caseid_val=np.array(caseid_val)\n",
    "\n",
    "caseid_test = np.unique(caseid_test)\n",
    "caseid_train = np.unique(caseid_train)\n",
    "caseid_val = np.unique(caseid_val)\n",
    "\n",
    "print(len(caseid_test))\n",
    "print(len(caseid_train))\n",
    "print(len(caseid_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T06:44:05.730760Z",
     "start_time": "2020-12-12T06:44:05.724080Z"
    }
   },
   "outputs": [],
   "source": [
    "for p in path_list:\n",
    "    if p in caseid_train:\n",
    "        print('1')\n",
    "    if p in caseid_val:\n",
    "        print('2')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T06:44:13.993248Z",
     "start_time": "2020-12-12T06:44:13.986663Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(caseid_test,open('../../DL_model/caseid_test_new','wb'))\n",
    "pickle.dump(caseid_train,open('../../DL_model/caseid_train_new','wb'))\n",
    "pickle.dump(caseid_val,open('../../DL_model/caseid_val_new','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T13:50:37.291562Z",
     "start_time": "2020-12-12T13:50:37.284821Z"
    }
   },
   "outputs": [],
   "source": [
    "caseid_test = pickle.load(open('../../DL_model/caseid_test_new','rb'))\n",
    "caseid_val = pickle.load(open('../../DL_model/caseid_val_new','rb'))\n",
    "caseid_train = pickle.load(open('../../DL_model/caseid_train_new','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T13:35:40.196484Z",
     "start_time": "2020-12-12T13:35:40.190934Z"
    }
   },
   "outputs": [],
   "source": [
    "caseid_train=caseid_train.tolist()\n",
    "caseid_test=caseid_test.tolist()\n",
    "caseid_val=caseid_val.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T13:50:45.652982Z",
     "start_time": "2020-12-12T13:50:41.378411Z"
    }
   },
   "outputs": [],
   "source": [
    "df_match = pd.read_csv('match_age_pass_20201211.csv')\n",
    "df_match['path'] = [f.split('.')[0]+'.csv' for f in df_match['path'].values.flatten()]\n",
    "df_match['set']=np.nan\n",
    "for i in range(len(df_match)):\n",
    "    if df_match.loc[i,'path'] in caseid_train:\n",
    "        df_match.loc[i,'set']= 0\n",
    "    if df_match.loc[i,'path'] in caseid_val:\n",
    "        df_match.loc[i,'set']= 1\n",
    "    if df_match.loc[i,'path'] in caseid_test:\n",
    "        df_match.loc[i,'set']= 2\n",
    "df_match       \n",
    "df_match.dropna(subset=['set'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T13:51:25.550311Z",
     "start_time": "2020-12-12T13:51:25.354281Z"
    }
   },
   "outputs": [],
   "source": [
    "df_match.to_csv('match_age_pass_setvalue_20201212.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T13:37:42.078233Z",
     "start_time": "2020-12-12T13:37:42.071883Z"
    }
   },
   "outputs": [],
   "source": [
    "df_match.sort_values(by=['Value'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T13:50:10.932408Z",
     "start_time": "2020-12-12T13:50:10.793069Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "df_opid = df_match.drop_duplicates(['opid'],keep='last')\n",
    "print(len(df_opid))\n",
    "df_opid.to_csv('match_age_pass_opid(3923)_20201212.csv')\n",
    "\n",
    "df_train = df_match[df_match['set']==0]\n",
    "df_val = df_match[df_match['set']==1]\n",
    "df_test = df_match[df_match['set']==2]\n",
    "df_train.drop_duplicates(['opid'],keep='last',inplace=True)\n",
    "df_val.drop_duplicates(['opid'],keep='last',inplace=True)\n",
    "df_test.drop_duplicates(['opid'],keep='last',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T13:39:57.263142Z",
     "start_time": "2020-12-12T13:39:57.256390Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3185\n",
      "353\n",
      "385\n"
     ]
    }
   ],
   "source": [
    "print(len(df_train))\n",
    "print(len(df_val))\n",
    "print(len(df_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
